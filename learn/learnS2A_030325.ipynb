{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2ltUIFtSIRo"
   },
   "source": [
    "## Imports and Set up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j4bFtFg6LITX",
    "outputId": "9df07d30-f9fe-47c8-dd3b-1d6f3c3b75fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "df = pd.read_csv(\"../data/flocking_250305.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2Cd4Pf9SkM9"
   },
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "65bvpyHhL7Jw"
   },
   "outputs": [],
   "source": [
    "# df[\"NeighborDiffSum\"] = df[\"NeighborDiffSum\"].apply(lambda x: eval(x) if isinstance(x, str) else x)\n",
    "df[\"NeighborInfo\"] = df[\"NeighborInfo\"].apply(lambda x: eval(x) if isinstance(x, str) else x)\n",
    "df[\"Angle\"] = df[\"Angle\"].astype(float)\n",
    "\n",
    "\"\"\"\n",
    "group data according to each time step\n",
    "\"\"\"\n",
    "grouped = df.groupby(\"Step\").agg(list)\n",
    "# neighbor_diff_sum = np.array(grouped[\"NeighborDiffSum\"].to_list())  # Shape: (num_steps, num_agents, 2)\n",
    "neighbor_info = np.array(grouped[\"NeighborInfo\"].to_list())  # Shape: (num_steps, num_agents, 2)\n",
    "angles = np.array(grouped[\"Angle\"].to_list()).reshape(len(grouped), len(grouped.iloc[0][\"Angle\"]), 1)  # Shape: (num_steps, num_agents, 1)\n",
    "\n",
    "delta_angle = np.zeros_like(angles)\n",
    "delta_angle[1:] = angles[1:] - angles[:-1] # Shape: (num_steps, num_agents, 1)\n",
    "\n",
    "grouped[\"deltaAngle\"] = delta_angle.reshape(len(grouped), -1).tolist()\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(neighbor_diff_sum, delta_angle, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(neighbor_info, delta_angle, test_size=0.2, random_state=42)\n",
    "\n",
    "# to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3I2uUuD3YS_I"
   },
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "id": "yOmLqtPSL9E_"
   },
   "outputs": [],
   "source": [
    "# define nn\n",
    "hidden_size_1 = 16\n",
    "hidden_size_2 = 8\n",
    "hidden_size_3 = 4\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(8, hidden_size_1),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size_1, hidden_size_2),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size_2, 1)\n",
    ")\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOwoH1dkvytH"
   },
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LN4XmiAjvuUX",
    "outputId": "63459eb3-3707-4510-8c58-9deda12b5f81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000], Loss: 0.1095\n",
      "Epoch [20/1000], Loss: 0.0943\n",
      "Epoch [30/1000], Loss: 0.0771\n",
      "Epoch [40/1000], Loss: 0.0692\n",
      "Epoch [50/1000], Loss: 0.0640\n",
      "Epoch [60/1000], Loss: 0.0611\n",
      "Epoch [70/1000], Loss: 0.0592\n",
      "Epoch [80/1000], Loss: 0.0581\n",
      "Epoch [90/1000], Loss: 0.0573\n",
      "Epoch [100/1000], Loss: 0.0568\n",
      "Epoch [110/1000], Loss: 0.0564\n",
      "Epoch [120/1000], Loss: 0.0561\n",
      "Epoch [130/1000], Loss: 0.0558\n",
      "Epoch [140/1000], Loss: 0.0555\n",
      "Epoch [150/1000], Loss: 0.0553\n",
      "Epoch [160/1000], Loss: 0.0550\n",
      "Epoch [170/1000], Loss: 0.0548\n",
      "Epoch [180/1000], Loss: 0.0545\n",
      "Epoch [190/1000], Loss: 0.0543\n",
      "Epoch [200/1000], Loss: 0.0541\n",
      "Epoch [210/1000], Loss: 0.0539\n",
      "Epoch [220/1000], Loss: 0.0537\n",
      "Epoch [230/1000], Loss: 0.0535\n",
      "Epoch [240/1000], Loss: 0.0534\n",
      "Epoch [250/1000], Loss: 0.0532\n",
      "Epoch [260/1000], Loss: 0.0530\n",
      "Epoch [270/1000], Loss: 0.0528\n",
      "Epoch [280/1000], Loss: 0.0526\n",
      "Epoch [290/1000], Loss: 0.0525\n",
      "Epoch [300/1000], Loss: 0.0524\n",
      "Epoch [310/1000], Loss: 0.0523\n",
      "Epoch [320/1000], Loss: 0.0522\n",
      "Epoch [330/1000], Loss: 0.0522\n",
      "Epoch [340/1000], Loss: 0.0521\n",
      "Epoch [350/1000], Loss: 0.0520\n",
      "Epoch [360/1000], Loss: 0.0519\n",
      "Epoch [370/1000], Loss: 0.0519\n",
      "Epoch [380/1000], Loss: 0.0518\n",
      "Epoch [390/1000], Loss: 0.0518\n",
      "Epoch [400/1000], Loss: 0.0517\n",
      "Epoch [410/1000], Loss: 0.0517\n",
      "Epoch [420/1000], Loss: 0.0516\n",
      "Epoch [430/1000], Loss: 0.0516\n",
      "Epoch [440/1000], Loss: 0.0515\n",
      "Epoch [450/1000], Loss: 0.0515\n",
      "Epoch [460/1000], Loss: 0.0515\n",
      "Epoch [470/1000], Loss: 0.0514\n",
      "Epoch [480/1000], Loss: 0.0514\n",
      "Epoch [490/1000], Loss: 0.0514\n",
      "Epoch [500/1000], Loss: 0.0513\n",
      "Epoch [510/1000], Loss: 0.0513\n",
      "Epoch [520/1000], Loss: 0.0513\n",
      "Epoch [530/1000], Loss: 0.0512\n",
      "Epoch [540/1000], Loss: 0.0512\n",
      "Epoch [550/1000], Loss: 0.0511\n",
      "Epoch [560/1000], Loss: 0.0511\n",
      "Epoch [570/1000], Loss: 0.0511\n",
      "Epoch [580/1000], Loss: 0.0510\n",
      "Epoch [590/1000], Loss: 0.0510\n",
      "Epoch [600/1000], Loss: 0.0510\n",
      "Epoch [610/1000], Loss: 0.0509\n",
      "Epoch [620/1000], Loss: 0.0509\n",
      "Epoch [630/1000], Loss: 0.0509\n",
      "Epoch [640/1000], Loss: 0.0508\n",
      "Epoch [650/1000], Loss: 0.0508\n",
      "Epoch [660/1000], Loss: 0.0507\n",
      "Epoch [670/1000], Loss: 0.0507\n",
      "Epoch [680/1000], Loss: 0.0507\n",
      "Epoch [690/1000], Loss: 0.0506\n",
      "Epoch [700/1000], Loss: 0.0506\n",
      "Epoch [710/1000], Loss: 0.0505\n",
      "Epoch [720/1000], Loss: 0.0505\n",
      "Epoch [730/1000], Loss: 0.0505\n",
      "Epoch [740/1000], Loss: 0.0504\n",
      "Epoch [750/1000], Loss: 0.0504\n",
      "Epoch [760/1000], Loss: 0.0503\n",
      "Epoch [770/1000], Loss: 0.0503\n",
      "Epoch [780/1000], Loss: 0.0502\n",
      "Epoch [790/1000], Loss: 0.0502\n",
      "Epoch [800/1000], Loss: 0.0501\n",
      "Epoch [810/1000], Loss: 0.0501\n",
      "Epoch [820/1000], Loss: 0.0500\n",
      "Epoch [830/1000], Loss: 0.0499\n",
      "Epoch [840/1000], Loss: 0.0499\n",
      "Epoch [850/1000], Loss: 0.0498\n",
      "Epoch [860/1000], Loss: 0.0497\n",
      "Epoch [870/1000], Loss: 0.0496\n",
      "Epoch [880/1000], Loss: 0.0495\n",
      "Epoch [890/1000], Loss: 0.0494\n",
      "Epoch [900/1000], Loss: 0.0492\n",
      "Epoch [910/1000], Loss: 0.0490\n",
      "Epoch [920/1000], Loss: 0.0488\n",
      "Epoch [930/1000], Loss: 0.0486\n",
      "Epoch [940/1000], Loss: 0.0483\n",
      "Epoch [950/1000], Loss: 0.0481\n",
      "Epoch [960/1000], Loss: 0.0478\n",
      "Epoch [970/1000], Loss: 0.0476\n",
      "Epoch [980/1000], Loss: 0.0474\n",
      "Epoch [990/1000], Loss: 0.0472\n",
      "Epoch [1000/1000], Loss: 0.0470\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor.view(-1, 8))\n",
    "    loss = criterion(outputs, y_train_tensor.view(-1, 1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2EYSl8OwAWu"
   },
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HYPk_FgOwOYG",
    "outputId": "3ad4c6e5-4424-4557-b248-7344b1e9b039"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0406\n",
      "tensor([[-3.3530e-03],\n",
      "        [-3.4723e-03],\n",
      "        [-1.1513e-05],\n",
      "        ...,\n",
      "        [-5.1259e-02],\n",
      "        [ 3.4529e-02],\n",
      "        [ 5.1091e-02]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_tensor.view(-1, 8))\n",
    "    test_loss = criterion(y_pred, y_test_tensor.view(-1, 1))\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')\n",
    "    print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '../models/20250305_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
